{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "import tempfile\n",
    "from collections import OrderedDict, defaultdict\n",
    "import random\n",
    "\n",
    "#import mir_eval\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import mode as scipy_mode\n",
    "from sklearn.metrics import average_precision_score, r2_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glob\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of each representation\n",
    "npy_paths_clmr = sorted(glob.glob('features_our/clmr/*.npy'))\n",
    "npy_paths_musicnn = sorted(glob.glob('features_our/musicnn/*.npy'))\n",
    "npy_paths_jukebox_zeropad = sorted(glob.glob('features_our/jukebox/*.npy'))\n",
    "\n",
    "# Feature representations\n",
    "X_clmr = np.array([np.load(p) for p in npy_paths_clmr])\n",
    "X_musicnn = np.array([np.load(p) for p in npy_paths_musicnn])\n",
    "X_jukebox_zeropad = np.array([np.load(p) for p in npy_paths_jukebox_zeropad])\n",
    "\n",
    "# Labels\n",
    "y_clmr = np.array([os.path.split(p)[1].split('-')[0] for p in npy_paths_clmr])\n",
    "y_musicnn = np.array([os.path.split(p)[1].split('-')[0] for p in npy_paths_musicnn])\n",
    "y_jukebox_zeropad = np.array([os.path.split(p)[1].split('-')[0] for p in npy_paths_jukebox_zeropad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TO_ATTRS = {\n",
    "    \"dcase\": {\n",
    "        \"num_outputs\": 10,\n",
    "        \"output_type\": \"multiclass\",\n",
    "        \"labels\": \"\"\"airport, bus, metro, metro_station, park, public_square, shopping_mall, street_pedestrian, street_traffic, tram\"\"\".split(\n",
    "            \", \"\n",
    "        ),\n",
    "    }}\n",
    "\n",
    "PAPER_GRID = {\n",
    "    \"data_standardization\": [False, True],\n",
    "    \"hidden_layer_sizes\": [[], [512]],\n",
    "    \"batch_size\": [64, 256],\n",
    "    \"learning_rate\": [1e-5, 1e-4, 1e-3],\n",
    "    \"dropout_p\": [0.25, 0.5, 0.75],\n",
    "    \"l2_weight_decay\": [None, 1e-4, 1e-3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "        \"dataset\": None,\n",
    "        \"representation\": None,\n",
    "        \"data_standardization\": True,\n",
    "        \"hidden_layer_sizes\": [],\n",
    "        \"batch_size\": 64,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"dropout_input\": True,\n",
    "        \"dropout_p\": 0.5,\n",
    "        \"l2_weight_decay\": None,\n",
    "        \"max_num_epochs\": 300,\n",
    "        \"early_stopping_metric\": \"primary\",\n",
    "        \"early_stopping\": True,\n",
    "        \"early_stopping_eval_frequency\": 8,\n",
    "        \"early_stopping_boredom\": 256,\n",
    "        \"seed\": 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Clmr\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train_clmr, X_rem_clmr, y_train_clmr, y_rem_clmr = train_test_split(X_clmr,y_clmr, train_size=0.8)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "X_valid_clmr, X_test_clmr, y_valid_clmr, y_test_clmr = train_test_split(X_rem_clmr,y_rem_clmr, test_size=0.5)\n",
    "\n",
    "# Musicnn\n",
    "X_train_musicnn, X_rem_musicnn, y_train_musicnn, y_rem_musicnn = train_test_split(X_musicnn,y_musicnn, train_size=0.8)\n",
    "X_valid_musicnn, X_test_musicnn, y_valid_musicnn, y_test_musicnn = train_test_split(X_rem_musicnn,y_rem_musicnn, test_size=0.5)\n",
    "\n",
    "# Jukebox\n",
    "X_train_jukebox_zeropad, X_rem_jukebox_zeropad, y_train_jukebox_zeropad, y_rem_jukebox_zeropad = train_test_split(X_jukebox_zeropad,y_jukebox_zeropad, train_size=0.8)\n",
    "X_valid_jukebox_zeropad, X_test_jukebox_zeropad, y_valid_jukebox_zeropad, y_test_jukebox_zeropad = train_test_split(X_rem_jukebox_zeropad,y_rem_jukebox_zeropad, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_to_X = defaultdict(lambda: defaultdict(list))\n",
    "split_to_y = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "split_to_X[\"clmr\"][\"train\"] = X_train_clmr\n",
    "split_to_X[\"clmr\"][\"validation\"] = X_valid_clmr\n",
    "split_to_X[\"clmr\"][\"test\"] = X_test_clmr\n",
    "split_to_y[\"clmr\"][\"train\"] = y_train_clmr\n",
    "split_to_y[\"clmr\"][\"validation\"] = y_valid_clmr\n",
    "split_to_y[\"clmr\"][\"test\"] = y_test_clmr\n",
    "\n",
    "split_to_X[\"musicnn\"][\"train\"] = X_train_musicnn\n",
    "split_to_X[\"musicnn\"][\"validation\"] = X_valid_musicnn\n",
    "split_to_X[\"musicnn\"][\"test\"] = X_test_musicnn\n",
    "split_to_y[\"musicnn\"][\"train\"] = y_train_musicnn\n",
    "split_to_y[\"musicnn\"][\"validation\"] = y_valid_musicnn\n",
    "split_to_y[\"musicnn\"][\"test\"] = y_test_musicnn\n",
    "\n",
    "split_to_X[\"jukebox\"][\"train\"] = X_train_jukebox_zeropad\n",
    "split_to_X[\"jukebox\"][\"validation\"] = X_valid_jukebox_zeropad\n",
    "split_to_X[\"jukebox\"][\"test\"] = X_test_jukebox_zeropad\n",
    "split_to_y[\"jukebox\"][\"train\"] = y_train_jukebox_zeropad\n",
    "split_to_y[\"jukebox\"][\"validation\"] = y_valid_jukebox_zeropad\n",
    "split_to_y[\"jukebox\"][\"test\"] = y_test_jukebox_zeropad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features,\n",
    "        hidden_layer_sizes,\n",
    "        num_outputs,\n",
    "        dropout_input=True,\n",
    "        dropout_p=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        d = num_features\n",
    "        self.num_layers = 1\n",
    "        for i, ld in enumerate(hidden_layer_sizes):\n",
    "            setattr(self, f\"hidden_{i}\", nn.Linear(d, ld))\n",
    "            d = ld\n",
    "        self.output = nn.Linear(d, num_outputs)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        for i in range(self.num_layers):\n",
    "            x = getattr(self, f\"hidden_{i}\")(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    probe.parameters(),\n",
    "    lr=cfg[\"learning_rate\"],\n",
    "    weight_decay=0\n",
    "    if cfg[\"l2_weight_decay\"] is None\n",
    "    else cfg[\"l2_weight_decay\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_dict = {}\n",
    "le_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleMLP(\n",
       "  (hidden_0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe = SimpleMLP(\n",
    "            num_features = split_to_X[\"clmr\"][\"train\"].shape[1],\n",
    "            hidden_layer_sizes = [512],\n",
    "            num_outputs = DATASET_TO_ATTRS[\"dcase\"][\"num_outputs\"],\n",
    "            dropout_input=True,\n",
    "            dropout_p=0.25,\n",
    "        )\n",
    "\n",
    "probe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler_clmr = StandardScaler()\n",
    "std_scaler_clmr.fit(split_to_X[\"clmr\"][\"train\"])\n",
    "\n",
    "scaler_dict[\"clmr\"] = std_scaler_clmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le_clmr = preprocessing.LabelEncoder()\n",
    "le.fit_transform(split_to_y[\"clmr\"][\"train\"])\n",
    "\n",
    "le_dict[\"clmr\"] = le_clmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 2.308100700378418\n",
      "Epoch 20, loss 2.3520381450653076\n",
      "Epoch 30, loss 2.351431369781494\n",
      "Epoch 40, loss 2.4163386821746826\n",
      "Epoch 50, loss 2.3564860820770264\n",
      "Epoch 60, loss 2.3345210552215576\n",
      "Epoch 70, loss 2.302258253097534\n",
      "Epoch 80, loss 2.378150463104248\n",
      "Epoch 90, loss 2.4029898643493652\n",
      "Epoch 100, loss 2.3859221935272217\n",
      "Epoch 110, loss 2.4038095474243164\n",
      "Epoch 120, loss 2.397473096847534\n",
      "Epoch 130, loss 2.330629587173462\n",
      "Epoch 140, loss 2.3541345596313477\n",
      "Epoch 150, loss 2.360898494720459\n",
      "Epoch 160, loss 2.357152223587036\n",
      "Epoch 170, loss 2.285766839981079\n",
      "Epoch 180, loss 2.34651517868042\n",
      "Epoch 190, loss 2.358009099960327\n",
      "Epoch 200, loss 2.342772960662842\n",
      "Epoch 210, loss 2.2927374839782715\n",
      "Epoch 220, loss 2.400094985961914\n",
      "Epoch 230, loss 2.3891122341156006\n",
      "Epoch 240, loss 2.324869155883789\n",
      "Epoch 250, loss 2.3273675441741943\n",
      "Epoch 260, loss 2.4599697589874268\n",
      "Epoch 270, loss 2.3674144744873047\n",
      "Epoch 280, loss 2.2762556076049805\n",
      "Epoch 290, loss 2.390181303024292\n",
      "Epoch 300, loss 2.3858489990234375\n"
     ]
    }
   ],
   "source": [
    "import wandb as wandb_lib\n",
    "\n",
    "summarize_frequency = 10\n",
    "\n",
    "epoch = 0\n",
    "while True:\n",
    "    # Check if exceeded max num epochs\n",
    "    if epoch == cfg[\"max_num_epochs\"]:\n",
    "        break\n",
    "    # Create batch\n",
    "    idxs = random.sample(\n",
    "        list(range(X_train_clmr.shape[0])),\n",
    "        min(cfg[\"batch_size\"], X_train_clmr.shape[0]),\n",
    "    )\n",
    "    X, y = X_train_clmr[idxs], y_train_clmr[idxs]\n",
    "    X = std_scaler.transform(X)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_trans = le.fit_transform(y)\n",
    "    \n",
    "    X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    y = torch.tensor(y_trans, device=device)\n",
    "\n",
    "    # Update\n",
    "    optimizer.zero_grad()\n",
    "    loss = F.cross_entropy(input = probe(X), target =y )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch += 1\n",
    "    \n",
    "    # Summarize\n",
    "    if epoch % summarize_frequency == 0:\n",
    "        loss = loss.item()\n",
    "        print(\"Epoch {}, loss {}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Musicnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleMLP(\n",
       "  (hidden_0): Linear(in_features=4194, out_features=512, bias=True)\n",
       "  (output): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe = SimpleMLP(\n",
    "            num_features = split_to_X[\"musicnn\"][\"train\"].shape[1],\n",
    "            hidden_layer_sizes = [512],\n",
    "            num_outputs = DATASET_TO_ATTRS[\"dcase\"][\"num_outputs\"],\n",
    "            dropout_input=True,\n",
    "            dropout_p=0.25,\n",
    "        )\n",
    "\n",
    "probe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler_musicnn = StandardScaler()\n",
    "std_scaler_musicnn.fit(split_to_X[\"musicnn\"][\"train\"])\n",
    "\n",
    "scaler_dict[\"musicnn\"] = std_scaler_musicnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le_musicnn = preprocessing.LabelEncoder()\n",
    "le_musicnn.fit_transform(split_to_y[\"musicnn\"][\"train\"])\n",
    "\n",
    "le_dict[\"musicnn\"] = le_musicnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 2.2825276851654053\n",
      "Epoch 20, loss 2.278913736343384\n",
      "Epoch 30, loss 2.3021867275238037\n",
      "Epoch 40, loss 2.3278188705444336\n",
      "Epoch 50, loss 2.325681686401367\n",
      "Epoch 60, loss 2.2612669467926025\n",
      "Epoch 70, loss 2.282681703567505\n",
      "Epoch 80, loss 2.290393114089966\n",
      "Epoch 90, loss 2.265821695327759\n",
      "Epoch 100, loss 2.271136522293091\n",
      "Epoch 110, loss 2.299163579940796\n",
      "Epoch 120, loss 2.330639123916626\n",
      "Epoch 130, loss 2.285731315612793\n",
      "Epoch 140, loss 2.2961182594299316\n",
      "Epoch 150, loss 2.287040948867798\n",
      "Epoch 160, loss 2.337601661682129\n",
      "Epoch 170, loss 2.2923672199249268\n",
      "Epoch 180, loss 2.2931265830993652\n",
      "Epoch 190, loss 2.3046576976776123\n",
      "Epoch 200, loss 2.2912700176239014\n",
      "Epoch 210, loss 2.2954659461975098\n",
      "Epoch 220, loss 2.274556875228882\n",
      "Epoch 230, loss 2.291787624359131\n",
      "Epoch 240, loss 2.278048038482666\n",
      "Epoch 250, loss 2.2880165576934814\n",
      "Epoch 260, loss 2.3102943897247314\n",
      "Epoch 270, loss 2.286292314529419\n",
      "Epoch 280, loss 2.281397819519043\n",
      "Epoch 290, loss 2.317507028579712\n",
      "Epoch 300, loss 2.3175950050354004\n"
     ]
    }
   ],
   "source": [
    "import wandb as wandb_lib\n",
    "\n",
    "summarize_frequency = 10\n",
    "\n",
    "epoch = 0\n",
    "while True:\n",
    "    # Check if exceeded max num epochs\n",
    "    if epoch == cfg[\"max_num_epochs\"]:\n",
    "        break\n",
    "    # Create batch\n",
    "    idxs = random.sample(\n",
    "        list(range(X_train_musicnn.shape[0])),\n",
    "        min(cfg[\"batch_size\"], X_train_musicnn.shape[0]),\n",
    "    )\n",
    "    X, y = X_train_musicnn[idxs], y_train_musicnn[idxs]\n",
    "    X = std_scaler_musicnn.transform(X)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_trans = le.fit_transform(y)\n",
    "    \n",
    "    X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    y = torch.tensor(y_trans, device=device)\n",
    "\n",
    "    # Update\n",
    "    optimizer.zero_grad()\n",
    "    loss = F.cross_entropy(input = probe(X), target =y )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch += 1\n",
    "    \n",
    "    # Summarize\n",
    "    if epoch % summarize_frequency == 0:\n",
    "        loss = loss.item()\n",
    "        print(\"Epoch {}, loss {}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jukebox (0-pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleMLP(\n",
       "  (hidden_0): Linear(in_features=4800, out_features=512, bias=True)\n",
       "  (output): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe = SimpleMLP(\n",
    "            num_features = split_to_X[\"jukebox\"][\"train\"].shape[1],\n",
    "            hidden_layer_sizes = [512],\n",
    "            num_outputs = DATASET_TO_ATTRS[\"dcase\"][\"num_outputs\"],\n",
    "            dropout_input=True,\n",
    "            dropout_p=0.25,\n",
    "        )\n",
    "\n",
    "probe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler_jukebox = StandardScaler()\n",
    "std_scaler_jukebox.fit(split_to_X[\"jukebox\"][\"train\"])\n",
    "\n",
    "scaler_dict[\"jukebox\"] = std_scaler_jukebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le_jukebox = preprocessing.LabelEncoder()\n",
    "le_jukebox.fit_transform(split_to_y[\"jukebox\"][\"train\"])\n",
    "\n",
    "le_dict[\"jukebox\"] = le_jukebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 2.4042441844940186\n",
      "Epoch 20, loss 2.3660833835601807\n",
      "Epoch 30, loss 2.384331703186035\n",
      "Epoch 40, loss 2.40330171585083\n",
      "Epoch 50, loss 2.4249908924102783\n",
      "Epoch 60, loss 2.3597500324249268\n",
      "Epoch 70, loss 2.292440891265869\n",
      "Epoch 80, loss 2.4338154792785645\n",
      "Epoch 90, loss 2.4052882194519043\n",
      "Epoch 100, loss 2.3852698802948\n",
      "Epoch 110, loss 2.402383327484131\n",
      "Epoch 120, loss 2.4262704849243164\n",
      "Epoch 130, loss 2.3900556564331055\n",
      "Epoch 140, loss 2.375556230545044\n",
      "Epoch 150, loss 2.4089126586914062\n",
      "Epoch 160, loss 2.436285972595215\n",
      "Epoch 170, loss 2.396090269088745\n",
      "Epoch 180, loss 2.390254497528076\n",
      "Epoch 190, loss 2.4125072956085205\n",
      "Epoch 200, loss 2.4186441898345947\n",
      "Epoch 210, loss 2.350250244140625\n",
      "Epoch 220, loss 2.4532456398010254\n",
      "Epoch 230, loss 2.3498756885528564\n",
      "Epoch 240, loss 2.368086814880371\n",
      "Epoch 250, loss 2.3486831188201904\n",
      "Epoch 260, loss 2.3842172622680664\n",
      "Epoch 270, loss 2.3629508018493652\n",
      "Epoch 280, loss 2.4140963554382324\n",
      "Epoch 290, loss 2.3933892250061035\n",
      "Epoch 300, loss 2.37218976020813\n"
     ]
    }
   ],
   "source": [
    "import wandb as wandb_lib\n",
    "\n",
    "summarize_frequency = 10\n",
    "\n",
    "epoch = 0\n",
    "while True:\n",
    "    # Check if exceeded max num epochs\n",
    "    if epoch == cfg[\"max_num_epochs\"]:\n",
    "        break\n",
    "    # Create batch\n",
    "    idxs = random.sample(\n",
    "        list(range(X_train_jukebox_zeropad.shape[0])),\n",
    "        min(cfg[\"batch_size\"], X_train_jukebox_zeropad.shape[0]),\n",
    "    )\n",
    "    X, y = X_train_jukebox_zeropad[idxs], y_train_jukebox_zeropad[idxs]\n",
    "    X = std_scaler_jukebox.transform(X)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_trans = le.fit_transform(y)\n",
    "    \n",
    "    X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    y = torch.tensor(y_trans, device=device)\n",
    "\n",
    "    # Update\n",
    "    optimizer.zero_grad()\n",
    "    loss = F.cross_entropy(input = probe(X), target =y )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch += 1\n",
    "    \n",
    "    # Summarize\n",
    "    if epoch % summarize_frequency == 0:\n",
    "        loss = loss.item()\n",
    "        print(\"Epoch {}, loss {}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3/anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
